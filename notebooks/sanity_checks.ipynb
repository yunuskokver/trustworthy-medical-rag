{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Checks for Medical RAG\n",
    "This notebook demonstrates a minimal end-to-end pipeline:\n",
    "1. Load a MedQuAD question (held-out test set)\n",
    "2. Normalize the text\n",
    "3. Generate a dense embedding\n",
    "4. Retrieve top-*k* answers from FAISS\n",
    "5. Build a prompt and query GPT-4\n",
    "6. Compute a quick token-level F1 against the reference answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment & imports\n",
    "import os, faiss, json, yaml\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from preprocess import normalize_text\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration & initialize clients/models\n",
    "with open(\"../config.yaml\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "index = faiss.read_index(f\"../{cfg['paths']['index_path']}\")\n",
    "model = SentenceTransformer(cfg[\"models\"][\"embedding_model\"])\n",
    "\n",
    "def load_jsonl(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return [json.loads(l) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load held-out test set and retrieval corpus (answers)\n",
    "test_questions = [x[\"question\"] for x in load_jsonl(f\"../{cfg['paths']['test_questions_path']}\")]\n",
    "test_answers   = [x[\"answer\"]   for x in load_jsonl(f\"../{cfg['paths']['test_answers_path']}\")]\n",
    "train_answers  = [x[\"answer\"]   for x in load_jsonl(f\"../{cfg['paths']['train_answers_path']}\")]\n",
    "\n",
    "print(\"Test size:\", len(test_questions))\n",
    "print(\"Train (index) answers:\", len(train_answers))\n",
    "print(\"Sample question:\", test_questions[0])\n",
    "print(\"Reference answer:\", test_answers[0][:300], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed query & retrieve top-k\n",
    "q = normalize_text(test_questions[0])\n",
    "q_vec = model.encode([q])\n",
    "k = cfg[\"retrieval\"][\"k\"]\n",
    "D, I = index.search(q_vec, k)\n",
    "retrieved = [train_answers[i] for i in I[0]]\n",
    "\n",
    "print(\"Retrieved passages:\")\n",
    "for r in retrieved:\n",
    "    print(\"-\", r[:200], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt & query GPT-4\n",
    "def build_prompt(q, passages):\n",
    "    ctx = \"\\n\\n\".join(passages)\n",
    "    return f\"Context:\\n{ctx}\\n\\nQuestion: {q}\\nAnswer:\"\n",
    "\n",
    "prompt = build_prompt(q, retrieved)\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=cfg[\"models\"][\"openai_model\"],\n",
    "    messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "    temperature=cfg[\"evaluation\"][\"temperature\"],\n",
    "    max_tokens=cfg[\"evaluation\"][\"max_output_tokens\"]\n",
    ")\n",
    "\n",
    "pred_answer = resp.choices[0].message.content\n",
    "print(\"GPT-4 Answer:\\n\", pred_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick token-level F1\n",
    "def token_f1(pred, ref):\n",
    "    pt = nltk.word_tokenize(pred.lower()); rt = nltk.word_tokenize(ref.lower())\n",
    "    if not pt or not rt: return 0.0\n",
    "    common = set(pt) & set(rt)\n",
    "    if not common: return 0.0\n",
    "    precision = len(common) / len(pt)\n",
    "    recall    = len(common) / len(rt)\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "ref_answer = test_answers[0]\n",
    "print(\"Token-level F1:\", token_f1(pred_answer, ref_answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
